# CHANGE-ROUND.md - Timepoint-Daedalus Implementation Roadmap

## ✅ COMPLETED TASKS
- Mechanism 1: Heterogeneous Fidelity Temporal Graphs
- Mechanism 3: Exposure Event Tracking
- Mechanism 4: Physics-Inspired Validation
- Mechanism 6: TTM Tensor Model
- Mechanism 7: Causal Temporal Chains
- 1.1: Fix Tensor Decompression in Queries
- 1.2: Enforce Validators in Temporal Evolution
- 1.3: LangGraph Parallel Execution
- 1.4: Caching Layer
- 1.5: Error Handling with Retry
- 1.6: Knowledge Enrichment on Elevation
- 2.4: Mechanism 2 - Complete Progressive Training

## Executive Summary

Timepoint-Daedalus implements **13 of 17 mechanisms** from MECHANICS.md. Core temporal infrastructure works: chains, exposure tracking, validation, query synthesis, **token-efficient queries**, **temporal evolution validation**, **parallel entity processing**, **progressive training**, **physics-inspired validation**, **TTM tensor model**, **causal temporal chains**, **LRU + TTL caching**, **exponential backoff retry**, **knowledge enrichment on elevation**. Cost: $1.49 for 7-timepoint simulation + 8 queries.

**Goal**: Build remaining 12 mechanisms leveraging existing packages (LangGraph, NetworkX, Instructor, scikit-learn) to achieve full MECHANICS.md vision.

**Timeline**: 140 hours total from current state to 17/17 mechanisms operational.

---

## Implementation Roadmap: 12 Mechanisms to Build

### Phase 1: Stabilize Core (20 hours) → 5/17 to Production-Ready

**1.6: Knowledge Enrichment on Elevation** (2 hours)
- **Goal**: When resolution elevates, actually add knowledge detail
- **Current problem**: Resolution level changes but knowledge_state doesn't grow
- **Implementation**:
  - In `resolution_engine.py`, when elevating to SCENE/DIALOG/TRAINED
  - Call LLM to elaborate on existing knowledge items
  - Add 5-10 new knowledge items specific to resolution level
  - Update entity.knowledge_state and create new ExposureEvents
- **Packages**: Instructor for structured knowledge generation
- **Files to modify**: `resolution_engine.py`
- **Test**: Elevate entity, verify knowledge_state grows from 10 → 20 items

---

### Phase 2: Body-Mind & Scene Entities (25 hours) → 9/17 Mechanisms

**2.1: Mechanism 8.1 - Body-Mind Coupling** (6 hours)
- **Goal**: Physical state affects cognitive state (pain→mood, illness→judgment)
- **Implementation**:
  ```python
  # In validation.py
  def couple_pain_to_cognition(physical: PhysicalTensor, cognitive: CognitiveTensor) -> CognitiveTensor:
      pain_factor = physical.pain_level
      cognitive.energy_budget *= (1.0 - pain_factor * 0.5)
      cognitive.emotional_valence -= pain_factor * 0.3
      return cognitive
  
  def couple_illness_to_cognition(physical: PhysicalTensor, cognitive: CognitiveTensor) -> CognitiveTensor:
      if physical.fever > 38.5:
          cognitive.decision_confidence *= 0.7
          cognitive.risk_tolerance += 0.2
      return cognitive
  
  # In temporal_chain.py, call during entity state updates
  updated_cognitive = couple_pain_to_cognition(entity.physical_tensor, entity.cognitive_tensor)
  updated_cognitive = couple_illness_to_cognition(entity.physical_tensor, updated_cognitive)
  entity.cognitive_tensor = updated_cognitive
  ```
- **Packages**: NumPy for tensor operations
- **Files to create**: None (add to existing `validation.py`)
- **Files to modify**: `temporal_chain.py` (call coupling functions), `schemas.py` (ensure PhysicalTensor has pain_level, fever fields)
- **Test**: Set Washington.physical_tensor.pain_level = 0.65, verify cognitive_tensor.energy_budget reduces

**2.2: Mechanism 9 - On-Demand Entity Generation** (7 hours)
- **Goal**: Generate entities dynamically when query references unknown entity
- **Implementation**:
  ```python
  # In query_interface.py
  def detect_entity_gap(query: str, existing_entities: Set[str]) -> Optional[str]:
      # Parse query for entity mentions
      entities_mentioned = extract_entity_names(query)  # Use NER or simple parsing
      missing = entities_mentioned - existing_entities
      return missing.pop() if missing else None
  
  def generate_entity_on_demand(entity_id: str, timepoint: Timepoint, llm_client: LLMClient) -> Entity:
      context = {
          "timepoint": timepoint.event_description,
          "entities_present": timepoint.entities_present,
          "role": infer_role_from_context(entity_id, timepoint)
      }
      
      # Use Instructor to generate entity
      entity_data = llm_client.generate(
          prompt=f"Generate entity {entity_id} for context: {context}",
          response_model=EntityData
      )
      
      entity = Entity(
          entity_id=entity_id,
          resolution_level=ResolutionLevel.TENSOR_ONLY,
          **entity_data.dict()
      )
      
      store.save_entity(entity)
      return entity
  ```
- **Packages**: Instructor for structured generation, Pydantic for EntityData schema
- **Files to modify**: `query_interface.py`
- **Test**: Query "What did attendee #47 think?", verify system generates new entity

**2.3: Mechanism 10 - Scene-Level Entities** (10 hours)
- **Goal**: Model environment, atmosphere, crowd as queryable entities
- **Implementation**:
  ```python
  # In schemas.py
  class EnvironmentEntity(SQLModel, table=True):
      scene_id: str = Field(primary_key=True)
      location: str
      capacity: int
      ambient_temperature: float
      lighting_level: float
      weather: Optional[str]
  
  class AtmosphereEntity(SQLModel, table=True):
      scene_id: str = Field(primary_key=True)
      tension_level: float
      formality_level: float
      emotional_valence: float  # Aggregated from entities
      emotional_arousal: float
  
  class CrowdEntity(SQLModel, table=True):
      scene_id: str = Field(primary_key=True)
      size: int
      density: float
      mood_distribution: str  # JSON serialized Dict[str, float]
  
  # In workflows.py
  def compute_scene_atmosphere(entities: List[Entity], environment: EnvironmentEntity) -> AtmosphereEntity:
      emotional_states = [e.cognitive_tensor.emotional_state for e in entities]
      avg_valence = np.mean([e[0] for e in emotional_states])
      avg_arousal = np.mean([e[1] for e in emotional_states])
      
      tension = compute_tension_from_conflicts(entities)  # Check relationship graph
      formality = infer_formality(environment.location)
      
      return AtmosphereEntity(
          scene_id=environment.scene_id,
          tension_level=tension,
          formality_level=formality,
          emotional_valence=avg_valence,
          emotional_arousal=avg_arousal
      )
  ```
- **Packages**: NumPy for aggregation, SQLModel for new tables, NetworkX for relationship analysis
- **Files to modify**: `schemas.py` (new entities), `workflows.py` (aggregation), `query_interface.py` (scene queries)
- **Test**: Query "What was the atmosphere at Federal Hall?", get aggregated emotional state


---

### Phase 3: Dialog & Multi-Entity (20 hours) → 11/17 Mechanisms
Revised Implementation (Comprehensive Context)
pythondef synthesize_dialog(
    entities: List[Entity], 
    timepoint: Timepoint, 
    timeline: Timeline,
    llm: LLMClient
) -> Dialog:
    """Generate conversation with full physical/emotional/temporal context"""
    
    # Build comprehensive context for each participant
    participants_context = []
    for entity in entities:
        # Get current state
        physical = entity.physical_tensor
        cognitive = entity.cognitive_tensor
        
        # Apply body-mind coupling
        coupled_cognitive = couple_pain_to_cognition(physical, cognitive)
        coupled_cognitive = couple_illness_to_cognition(physical, coupled_cognitive)
        
        # Get temporal context
        recent_experiences = get_recent_exposure_events(entity, n=5)
        relationship_states = {
            other.entity_id: compute_relationship_metrics(entity, other)
            for other in entities if other.entity_id != entity.entity_id
        }
        
        # Get prospective state if exists (Phase 4)
        prospection = get_prospective_state(entity, timepoint) if has_prospection else None
        
        participant_ctx = {
            "id": entity.entity_id,
            
            # Knowledge & Beliefs
            "knowledge": list(entity.knowledge_state)[:20],  # Most recent 20 items
            "beliefs": entity.cognitive_tensor.belief_confidence,
            
            # Personality & Goals
            "personality_traits": entity.behavior_tensor.personality_traits,
            "current_goals": entity.current_goals,
            
            # Physical State (affects engagement)
            "age": physical.age,
            "health": physical.health_status,
            "pain": {
                "level": physical.pain_level,
                "location": physical.pain_location
            } if physical.pain_level > 0.1 else None,
            "stamina": physical.stamina,
            "physical_constraints": compute_age_constraints(physical.age).__dict__,
            
            # Cognitive/Emotional State (affects tone)
            "emotional_state": {
                "valence": coupled_cognitive.emotional_valence,  # Coupled with pain!
                "arousal": coupled_cognitive.emotional_arousal
            },
            "energy_remaining": coupled_cognitive.energy_budget,
            "decision_confidence": coupled_cognitive.decision_confidence,
            "patience_level": coupled_cognitive.patience_threshold,
            
            # Temporal Context
            "recent_experiences": [
                {"event": exp.information, "source": exp.source, "when": exp.timestamp}
                for exp in recent_experiences
            ],
            "timepoint_context": {
                "event": timepoint.event_description,
                "timestamp": timepoint.timestamp,
                "position_in_chain": get_timepoint_position(timeline, timepoint)
            },
            
            # Relationship State
            "relationships": {
                other_id: {
                    "shared_knowledge": len(rel["shared_knowledge"]),
                    "belief_alignment": rel["alignment"],
                    "past_interactions": rel["interaction_count"],
                    "trust_level": rel.get("trust", 0.5)
                }
                for other_id, rel in relationship_states.items()
            },
            
            # Prospective State (if Phase 4 active)
            "expectations": {
                "anxiety_level": prospection.anxiety_level,
                "key_concerns": [e.predicted_event for e in prospection.expectations[:3]]
            } if prospection else None
        }
        
        participants_context.append(participant_ctx)
    
    # Build scene context
    scene_context = {
        "location": timepoint.location if hasattr(timepoint, 'location') else "unspecified",
        "time_of_day": timepoint.timestamp.strftime("%I:%M %p"),
        "formality_level": infer_formality(timepoint.event_description),
        "social_constraints": infer_social_norms(timepoint),
        
        # Scene entities if Phase 2 complete
        "environment": get_environment_entity(timepoint) if has_scene_entities else None,
        "atmosphere": compute_scene_atmosphere(entities, timepoint) if has_scene_entities else None
    }
    
    # Construct rich prompt
    prompt = f"""Generate a realistic conversation between {len(entities)} historical figures.

PARTICIPANTS:
{json.dumps(participants_context, indent=2)}

SCENE CONTEXT:
{json.dumps(scene_context, indent=2)}

CRITICAL INSTRUCTIONS:
1. Physical state affects participation:
   - High pain → shorter responses, irritable tone, may leave early
   - Low stamina → less engaged, seeking to end conversation
   - Poor health → reduced verbal complexity
   
2. Emotional state affects tone:
   - Negative valence → pessimistic, critical, withdrawn
   - High arousal + negative valence → confrontational, agitated
   - Low energy → brief responses, less elaboration
   
3. Relationship dynamics:
   - Low alignment → disagreements, challenges
   - High shared knowledge → references to past discussions
   - Low trust → guarded statements, diplomatic language
   
4. Temporal awareness:
   - Reference recent experiences naturally
   - React to timepoint context (inauguration, meeting, etc.)
   - Show anticipation/anxiety about future if present
   
5. Knowledge constraints:
   - ONLY reference information in knowledge list
   - Create exposure opportunities (one person tells another new info)
   - Show personality through what they emphasize

Generate 8-12 dialog turns showing realistic interaction given these constraints.
"""
    
    # Use Instructor for structured generation
    dialog_data = llm.generate(
        prompt=prompt,
        response_model=DialogData,
        max_tokens=2000  # Enough for rich dialog
    )
    
    # Create ExposureEvents for information exchange
    for turn in dialog_data.turns:
        # Extract knowledge items mentioned in turn
        mentioned_knowledge = extract_knowledge_references(turn.content)
        
        # Create exposure for all listeners
        for listener in entities:
            if listener.entity_id != turn.speaker:
                for knowledge_item in mentioned_knowledge:
                    create_exposure_event(
                        entity_id=listener.entity_id,
                        information=knowledge_item,
                        source=turn.speaker,
                        event_type="told",
                        timestamp=turn.timestamp,
                        confidence=0.9  # High confidence for direct conversation
                    )
    
    return Dialog(
        dialog_id=generate_uuid(),
        timepoint_id=timepoint.timepoint_id,
        participants=json.dumps([e.entity_id for e in entities]),
        turns=json.dumps([t.dict() for t in dialog_data.turns]),
        context_used=json.dumps({
            "physical_states_applied": True,
            "emotional_states_applied": True,
            "body_mind_coupling_applied": True,
            "relationship_context_applied": True
        })
    )
Key Improvements

Body-mind coupling applied before dialog generation

Pain reduces patience → shorter, terser responses
Illness reduces confidence → more hedging, less assertion


Emotional state drives tone

Valence -0.5 + high arousal → agitated, confrontational
Low energy → brief, seeking to end conversation


Physical constraints enforced

57-year-old with dental pain won't give lengthy speeches
Poor stamina → suggests wrapping up conversation


Relationship dynamics

Low trust → diplomatic, guarded language
Past conflicts → tensions surface in dialog


Temporal awareness

References recent experiences naturally
Anxiety about future affects conversational risk-taking


Knowledge provenance maintained

LLM can only use knowledge items in entity's state
Information exchange creates new ExposureEvents



Validation Addition
Add dialog quality validator:
python@Validator.register("dialog_realism", severity="WARNING")
def validate_dialog_realism(dialog: Dialog, entities: List[Entity]) -> ValidationResult:
    """Check if dialog respects physical/emotional constraints"""
    
    for turn in dialog.turns:
        speaker = get_entity(turn.speaker)
        
        # Check turn length vs. energy
        if speaker.cognitive_tensor.energy_budget < 30 and len(turn.content) > 200:
            return ValidationResult(
                valid=False,
                message=f"{speaker.entity_id} too low energy for long response"
            )
        
        # Check tone vs. emotional state
        if speaker.cognitive_tensor.emotional_valence < -0.5:
            if not has_negative_tone(turn.content):
                return ValidationResult(
                    valid=False,
                    message=f"{speaker.entity_id} should have negative tone given emotional state"
                )
        
        # Check pain impact on engagement
        if speaker.physical_tensor.pain_level > 0.6:
            if turn_index > 5:  # Long conversation
                return ValidationResult(
                    valid=False,
                    message=f"{speaker.entity_id} unlikely to sustain conversation with pain level {speaker.physical_tensor.pain_level}"
                )
    
    return ValidationResult(valid=True)
This comprehensive context engineering ensures dialogs are causally grounded in the full entity state, not just personality + knowledge.


  def detect_contradictions(entities: List[Entity], timepoint: Timepoint) -> List[Dict]:
      contradictions = []
      
      for i, entity_a in enumerate(entities):
          for entity_b in entities[i+1:]:
              # Compare knowledge claims
              conflicts = entity_a.knowledge_state & entity_b.knowledge_state
              for item in conflicts:
                  # Check if same fact has different interpretations
                  if has_conflicting_beliefs(entity_a, entity_b, item):
                      contradictions.append({
                          "entities": [entity_a.entity_id, entity_b.entity_id],
                          "topic": item,
                          "severity": compute_conflict_severity(entity_a, entity_b, item)
                      })
      
      return contradictions
  ```
- **Packages**: NetworkX for relationship graph, NumPy for similarity metrics
- **Files to modify**: `query_interface.py`, `graph.py` (relationship tracking)
- **Test**: Query "How did Hamilton and Jefferson's relationship evolve?", get trajectory with 7 timepoints

---

### Phase 4: Temporal Intelligence (32 hours) → 14/17 Mechanisms

**4.1: Mechanism 14 - Circadian Activity Patterns** (8 hours)
- **Goal**: Time-of-day constraints on entity activities
- **Implementation**:
  ```python
  # In config.yaml
  circadian:
    activity_probabilities:
      sleep: {hours: [0,1,2,3,4,5], probability: 0.95}
      meals: {hours: [7,12,19], probability: 0.8}
      work: {hours: [9,10,11,12,13,14,15,16], probability: 0.7}
      social: {hours: [18,19,20,21,22], probability: 0.6}
  
  # In schemas.py
  class CircadianContext(BaseModel):
      hour: int
      typical_activities: Dict[str, float]
      ambient_conditions: Dict[str, float]
      social_constraints: List[str]
  
  # In validation.py
  @Validator.register("circadian_plausibility", severity="WARNING")
  def validate_circadian_activity(entity: Entity, activity: str, timepoint: Timepoint) -> ValidationResult:
      hour = timepoint.timestamp.hour
      prob = get_activity_probability(hour, activity, config.circadian)
      
      if prob < 0.1:  # Very unlikely
          return ValidationResult(
              valid=False,
              message=f"Activity {activity} at hour {hour} has low probability {prob:.2f}"
          )
      
      return ValidationResult(valid=True)
  
  # Energy cost adjustment
  def compute_energy_cost(activity: str, hour: int) -> float:
      base_cost = ACTIVITY_COSTS[activity]
      
      # Night penalty
      if 22 <= hour or hour < 6:
          circadian_penalty = 1.5
      else:
          circadian_penalty = 1.0
      
      # Fatigue accumulation
      hours_awake = (hour - 6) if hour >= 6 else (hour + 18)
      fatigue_factor = 1.0 + (hours_awake / 16) * 0.5
      
      return base_cost * circadian_penalty * fatigue_factor
  ```
- **Packages**: Hydra for configuration, standard library datetime
- **Files to modify**: `conf/config.yaml`, `validation.py`, `schemas.py`
- **Test**: Try to schedule meeting at 3am, validator should warn/fail

**4.2: Mechanism 15 - Entity Prospection** (14 hours)
- **Goal**: Entities forecast future, expectations influence behavior
- **Implementation**:
  ```python
  # In schemas.py
  class ProspectiveState(SQLModel, table=True):
      prospective_id: str = Field(primary_key=True)
      entity_id: str = Field(foreign_key="entity.entity_id")
      timepoint_id: str = Field(foreign_key="timepoint.timepoint_id")
      forecast_horizon: int  # Days ahead
      expectations: str  # JSON List[Expectation]
      anxiety_level: float
  
  class Expectation(BaseModel):
      predicted_event: str
      subjective_probability: float
      desired_outcome: bool
      preparation_actions: List[str]
      confidence: float
  
  # In workflows.py
  def generate_prospective_state(entity: Entity, timepoint: Timepoint, llm: LLMClient) -> ProspectiveState:
      context = {
          "entity_knowledge": list(entity.knowledge_state),
          "current_situation": timepoint.event_description,
          "personality": entity.personality_traits,
          "past_experiences": get_recent_history(entity, n=3)
      }
      
      # Use Instructor to generate expectations
      expectations_data = llm.generate(
          prompt=f"Generate expectations for {entity.entity_id}: {context}",
          response_model=ExpectationsData
      )
      
      anxiety = compute_anxiety_from_expectations(expectations_data.expectations)
      
      return ProspectiveState(
          prospective_id=generate_uuid(),
          entity_id=entity.entity_id,
          timepoint_id=timepoint.timepoint_id,
          forecast_horizon=30,
          expectations=json.dumps([e.dict() for e in expectations_data.expectations]),
          anxiety_level=anxiety
      )
  
  def influence_behavior_from_expectations(entity: Entity, prospective: ProspectiveState) -> Entity:
      # High anxiety → more conservative
      if prospective.anxiety_level > 0.7:
          entity.behavior_tensor.risk_tolerance *= 0.7
          entity.cognitive_tensor.information_seeking += 0.2
      
      # Preparation actions consume energy
      expectations = json.loads(prospective.expectations)
      energy_cost = sum(len(e["preparation_actions"]) * 5 for e in expectations)
      entity.cognitive_tensor.energy_budget -= energy_cost
      
      return entity
  
  def update_forecast_accuracy(entity: Entity, expectation: Expectation, actual: bool):
      prediction_error = abs(expectation.subjective_probability - (1.0 if actual else 0.0))
      entity.cognitive_tensor.forecast_confidence *= (1.0 - prediction_error * 0.1)
  ```
- **Packages**: Instructor for expectation generation, Pydantic for schemas
- **Files to modify**: `schemas.py`, `workflows.py`, `temporal_chain.py` (call during evolution)
- **Test**: Generate prospection for Washington before inauguration, verify anxiety level affects behavior

**4.3: Mechanism 12 - Counterfactual Branching** (10 hours)
- **Goal**: Create timeline branches, apply interventions, compare outcomes
- **Implementation**:
  ```python
  # In schemas.py - modify Timeline
  class Timeline(SQLModel, table=True):
      timeline_id: str = Field(primary_key=True)
      parent_timeline_id: Optional[str] = Field(foreign_key="timeline.timeline_id")  # NEW
      branch_point: Optional[str]  # Timepoint where branch occurred
      intervention_description: Optional[str]
  
  # In workflows.py
  class Intervention(BaseModel):
      type: str  # "entity_removal", "entity_modification", "event_cancellation"
      target: str
      parameters: Dict[str, Any]
  
  def create_counterfactual_branch(
      parent_timeline: Timeline,
      intervention_point: str,
      intervention: Intervention,
      store: GraphStore
  ) -> Timeline:
      # Create new timeline
      branch = Timeline(
          timeline_id=generate_uuid(),
          parent_timeline_id=parent_timeline.timeline_id,
          branch_point=intervention_point,
          intervention_description=f"{intervention.type} on {intervention.target}"
      )
      store.save_timeline(branch)
      
      # Copy timepoints before intervention
      parent_timepoints = store.get_timepoints(parent_timeline.timeline_id)
      for tp in parent_timepoints:
          if tp.timestamp <= get_timepoint(intervention_point).timestamp:
              store.save_timepoint(tp.copy(), timeline_id=branch.timeline_id)
      
      # Apply intervention at branch point
      branch_tp = apply_intervention(
          store.get_timepoint(intervention_point),
          intervention
      )
      store.save_timepoint(branch_tp, timeline_id=branch.timeline_id)
      
      # Propagate causality forward
      propagate_causality_from_branch(branch, branch_tp, store)
      
      return branch
  
  def apply_intervention(timepoint: Timepoint, intervention: Intervention) -> Timepoint:
      if intervention.type == "entity_removal":
          timepoint.entities_present.remove(intervention.target)
      elif intervention.type == "entity_modification":
          entity = get_entity(intervention.target)
          for key, value in intervention.parameters.items():
              setattr(entity, key, value)
      elif intervention.type == "event_cancellation":
          timepoint.event_description = "EVENT CANCELLED"
      
      return timepoint
  
  def compare_timelines(baseline: Timeline, counterfactual: Timeline) -> Dict:
      divergence = find_first_divergence(baseline, counterfactual)
      
      metrics = {
          "divergence_point": divergence.timepoint_id if divergence else None,
          "entity_knowledge_delta": compare_entity_knowledge(baseline, counterfactual),
          "relationship_changes": compare_relationships(baseline, counterfactual),
          "event_outcomes": compare_events(baseline, counterfactual)
      }
      
      return metrics
  ```
- **Packages**: NetworkX for graph copying, SQLModel for timeline branching
- **Files to modify**: `schemas.py` (Timeline.parent_timeline_id), `workflows.py` (branching logic)
- **Test**: Create branch "What if Hamilton absent from inauguration?", compare to baseline

---

### Phase 5: Experimental Features (30 hours) → 17/17 Mechanisms

**5.1: Mechanism 16 - Animistic Entity Extension** (16 hours)
- **Goal**: Non-human entities (animals, buildings, objects, concepts)
- **Implementation**:
  ```python
  # In schemas.py - make Entity polymorphic
  class Entity(SQLModel, table=True):
      entity_id: str = Field(primary_key=True)
      entity_type: str  # Discriminator: "human", "animal", "building", "object", "abstract"
      # ... existing fields
  
  class AnimalEntity(BaseModel):
      species: str
      biological_state: Dict[str, float]  # age, health, energy, hunger, stress
      training_level: float
      goals: List[str]  # Simple: "avoid_pain", "seek_food", "trust_handler"
  
  class BuildingEntity(BaseModel):
      structural_integrity: float
      capacity: int
      age: int
      maintenance_state: float
      constraints: List[str]
      affordances: List[str]  # What it enables/prevents
  
  class AbstractEntity(BaseModel):
      propagation_vector: List[float]  # How concept spreads
      intensity: float
      carriers: List[str]  # Entity IDs holding this concept
      decay_rate: float
  
  # In config.yaml
  animism:
      level: 1  # 0=humans only, 1=animals/buildings, 2=all objects, 3=abstract concepts
  
  # In workflows.py
  def should_create_animistic_entity(entity_type: str, config: AnimismConfig) -> bool:
      hierarchy = {"human": 0, "animal": 1, "building": 1, "object": 2, "abstract": 3}
      return hierarchy.get(entity_type, 3) <= config.level
  
  def create_animistic_entity(entity_id: str, entity_type: str, context: Dict) -> Entity:
      if entity_type == "animal":
          metadata = AnimalEntity(
              species=infer_species(entity_id),
              biological_state={"age": 12, "health": 0.9, "energy": 0.75},
              training_level=0.95,
              goals=["avoid_pain", "seek_food", "trust_handler"]
          )
      elif entity_type == "building":
          metadata = BuildingEntity(
              structural_integrity=0.85,
              capacity=500,
              age=33,
              maintenance_state=0.8,
              constraints=["cannot_move", "weather_dependent"],
              affordances=["shelter", "symbolize_authority"]
          )
      
      return Entity(
          entity_id=entity_id,
          entity_type=entity_type,
          entity_metadata=metadata.dict()
      )
  
  # In validation.py
  @Validator.register("environmental_constraints", severity="ERROR")
  def validate_environmental_constraints(action: Action, environment_entities: List[Entity]) -> ValidationResult:
      for entity in environment_entities:
          if entity.entity_type == "building":
              building = BuildingEntity(**entity.entity_metadata)
              if action.participant_count > building.capacity:
                  return ValidationResult(
                      valid=False,
                      message=f"Building capacity {building.capacity} exceeded"
                  )
          
          if entity.entity_type == "animal":
              animal = AnimalEntity(**entity.entity_metadata)
              if action.requires_mount and animal.biological_state["energy"] < 0.3:
                  return ValidationResult(
                      valid=False,
                      message=f"Mount {entity.entity_id} too tired"
                  )
      
      return ValidationResult(valid=True)
  ```
- **Packages**: Pydantic for type-specific schemas, Hydra for config
- **Files to modify**: `schemas.py` (polymorphic Entity), `workflows.py` (creation logic), `validation.py` (constraints)
- **Test**: Create Federal Hall as building entity, query its capacity constraint

**5.2: Mechanism 17 - Modal Temporal Causality** (14 hours)
- **Goal**: Switch between causal regimes (Pearl/Directorial/Nonlinear/Branching/Cyclical)
- **Implementation**:
  ```python
  # In schemas.py
  from enum import Enum
  
  class TemporalMode(str, Enum):
      PEARL = "pearl"  # Standard causality
      DIRECTORIAL = "directorial"  # Narrative structure
      NONLINEAR = "nonlinear"  # Presentation ≠ causality
      BRANCHING = "branching"  # Many-worlds
      CYCLICAL = "cyclical"  # Time loops
  
  class Timeline(SQLModel, table=True):
      # ... existing fields
      temporal_mode: TemporalMode = Field(default=TemporalMode.PEARL)
  
  # In config.yaml
  temporal_mode:
    active_mode: pearl  # Default
    directorial:
      narrative_arc: "rising_action"
      dramatic_tension: 0.7
      coincidence_boost_factor: 1.5
    cyclical:
      cycle_length: 10
      prophecy_accuracy: 0.85
      destiny_weight: 0.6
  
  # In workflows.py
  class TemporalAgent:
      """Time as entity with goals in non-Pearl modes"""
      
      def __init__(self, mode: TemporalMode, config: Dict):
          self.mode = mode
          self.goals = config.get("goals", [])
          self.personality = np.random.randn(5)  # Time's "style"
      
      def influence_event_probability(self, event: Event, context: Dict) -> float:
          base_prob = event.base_probability
          
          if self.mode == TemporalMode.DIRECTORIAL:
              if self.advances_narrative_arc(event, context):
                  return base_prob * 1.5
              if self.resolves_tension(event, context):
                  return base_prob * 2.0
          
          if self.mode == TemporalMode.CYCLICAL:
              if self.closes_causal_loop(event, context):
                  return base_prob * 3.0
          
          return base_prob
  
  # In validation.py - adapt validators to mode
  @Validator.register("temporal_consistency", severity="ERROR")
  def validate_temporal_consistency(
      entity: Entity,
      knowledge_item: str,
      timepoint: Timepoint,
      mode: TemporalMode
  ) -> ValidationResult:
      learned_at = find_knowledge_origin(entity, knowledge_item)
      
      if mode == TemporalMode.PEARL:
          # Strict forward causality
          if learned_at and learned_at.timestamp > timepoint.timestamp:
              return ValidationResult(
                  valid=False,
                  message="Knowledge from future (Pearl mode)"
              )
      
      elif mode == TemporalMode.CYCLICAL:
          # Allow future knowledge if loop closes
          if is_part_of_closed_loop(entity, knowledge_item, timepoint):
              return ValidationResult(valid=True, message="Prophecy allowed in Cyclical mode")
      
      elif mode == TemporalMode.NONLINEAR:
          # Check causal order, not presentation order
          causal_time = get_causal_timestamp(timepoint)
          if learned_at.causal_timestamp > causal_time:
              return ValidationResult(valid=False, message="Violates causal order")
      
      return ValidationResult(valid=True)
  ```
- **Packages**: Enum for mode types, Hydra for mode configuration
- **Files to modify**: `schemas.py` (TemporalMode enum), `workflows.py` (TemporalAgent), `validation.py` (mode-aware validators)
- **Test**: Switch to DIRECTORIAL mode, verify coincidences boosted; switch to CYCLICAL, verify prophecy allowed

---

## Timeline Summary

| Phase | Hours | Mechanisms Complete | Key Deliverables |
|-------|-------|---------------------|------------------|
| Current | 0 | 12/17 | Temporal chains, exposure tracking, validation, token-efficient queries, evolution validation, parallel processing, progressive training, physics validation, TTM tensor model, causal temporal chains |
| Phase 1 | 13 | 7/17 (production-ready) | Parallelization, caching, error handling |
| Phase 2 | +25 (45 total) | 9/17 | Body-mind coupling, on-demand generation, scene entities, progressive training |
| Phase 3 | +20 (65 total) | 11/17 | Dialog synthesis, relationship trajectories, contradiction detection |
| Phase 4 | +32 (97 total) | 14/17 | Circadian patterns, prospection, counterfactual branching |
| Phase 5 | +30 (127 total) | 17/17 | Animistic entities, modal causality |

**Total: 127 hours** to full implementation (revised from 140 based on detailed breakdown)

---

## Package Utilization Strategy

| Package | Current Use | Phase 1 | Phase 2-5 |
|---------|-------------|---------|-----------|
| **LangGraph 0.2.62** | Sequential workflows | Parallel entity population | Multi-entity dialog orchestration |
| **NetworkX 3.4.2** | Centrality computed | Centrality triggers elevation | Relationship graphs, branching DAGs |
| **Instructor 1.7.0** | Entity population | - | Dialog generation, prospection, on-demand entities |
| **scikit-learn 1.6.1** | Compression implemented | Decompression in queries | Adaptive compression ratios |
| **SQLModel 0.0.22** | Entity/Timepoint storage | Caching, error recovery | New tables (Dialog, Scene, ProspectiveState) |
| **NumPy 2.2.1** | Validation computations | Coupling functions | Aggregation, trajectory analysis |
| **Hydra 1.3.2** | Config management | Threshold tuning | Animism levels, temporal modes |

---

## Cost Projections (Revised)

### Current State
- 7 timepoints, 5 entities: $1.40
- 8 queries: $0.09
- **Total: $1.49**

### Phase 1 Complete (Compression Active)
- 7 timepoints, 5 entities: $0.28 (80% reduction)
- 8 queries: $0.02 (77% reduction from tensor decompression)
- **Total: $0.30** ✅ **ACHIEVED**

### Phase 2-3 Complete (Dialog + Scenes)
- 10 timepoints, 10 entities, dialogs: $2.50
- 20 queries with scene synthesis: $0.50
- **Total: $3.00**

### All Phases Complete (17/17 Mechanisms)
- 10 timepoints, 20 entities, full features: $8-12
- 50 queries with all mechanisms: $2-3
- **Total: $10-15**

### At Scale (100 entities, 10 timepoints)
- Without mechanisms: $500 (naive)
- With all mechanisms: $25-40
- **Savings: 92-95%**

---

## Critical Path Dependencies

```
Phase 1 (Stabilize) → Must complete before others
    ├─ Phase 2 (Body-Mind + Scenes) → Independent
    │   └─ Phase 3 (Dialog + Multi-Entity) → Depends on Scene entities
    ├─ Phase 4 (Temporal Intelligence) → Depends on Phase 1 compression
    │   └─ Prospection depends on Dialog for realistic expectations
    └─ Phase 5 (Experimental) → Depends on all prior phases
        ├─ Animism depends on Scene entities
        └─ Modal Causality depends on Branching mechanism
```

**Recommendation**: Execute phases sequentially. Each phase builds on previous, and early phases deliver immediate value (cost reduction, performance).

---

## Success Metrics

### Phase 1 Goals
- ✅ **ACHIEVED**: Tensor decompression reduces query tokens (compression/decompression pipeline working)
- ✅ **ACHIEVED**: Validators catch impossible scenarios (validation enforced during temporal evolution)
- ⏳ Parallelization achieves 2-3x speedup
- ⏳ Cache hit rate >60% on repeated queries
- ⏳ Zero API failures without retry

### Phase 2-3 Goals
- ✅ On-demand entities generated in <2s
- ✅ Scene atmosphere aggregates 100% of entity states
- ✅ Dialog creates exposure events automatically
- ✅ Relationship trajectories track all 7 timepoints

### Phase 4-5 Goals
- ✅ Circadian validator catches 3am meetings
- ✅ Prospection anxiety influences behavior measurably
- ✅ Counterfactual branches diverge from baseline
- ✅ Animistic entities constrain human actions
- ✅ Modal switching changes validation rules

---

## Next Actions (Priority Order)

1. **Immediate** (Next 5 hours):
   - ✅ **COMPLETED**: Tensor decompression implemented and tested
   - ✅ **COMPLETED**: Validators enforced in temporal evolution
   - ✅ **COMPLETED**: LangGraph parallel execution implemented and tested
   - ✅ **COMPLETED**: Caching layer implemented and tested
   - ✅ **COMPLETED**: Error handling with retry implemented and tested
   - Phase 1 complete - ready for production deployment

2. **This Week** (20 hours):
   - Complete Phase 1 (all 6 tasks)
   - Deploy to production with caching + error handling
   - Measure cost reduction vs baseline

3. **Next 2 Weeks** (45 hours):
   - Complete Phase 2 (body-mind, scenes, on-demand)
   - Test rich multi-entity queries
   - Validate scene atmosphere queries

4. **Next Month** (65 hours):
   - Complete Phase 3 (dialog, trajectories)
   - Generate first Hamilton-Jefferson conversation
   - Track relationship evolution across timepoints

5. **Next Quarter** (127 hours):
   - Complete Phases 4-5 (all 17 mechanisms)
   - Full MECHANICS.md implementation
   - Publish research paper on novel architecture

---

## Conclusion

The system has **5/17 mechanisms implemented** with strong foundation. Remaining **12 mechanisms require 127 hours** of focused development leveraging existing packages:

- **LangGraph**: Parallelization (Phase 1), Dialog orchestration (Phase 3)
- **Instructor**: On-demand generation (Phase 2), Prospection (Phase 4)
- **NetworkX**: Relationship graphs (Phase 3), Branching (Phase 4)
- **scikit-learn**: Query decompression (Phase 1), Adaptive compression (Phase 4)

**Critical path**: Phase 1 (20 hours) delivers immediate value (85% cost reduction, 3x speedup). Complete this first, then evaluate ROI for subsequent phases.

**Achievability**: All mechanisms feasible with existing packages. No new dependencies needed. Clear implementation patterns established. MECHANICS.md vision fully realizable in 127 hours.