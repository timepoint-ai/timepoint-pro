# ğŸ”¥ Real LLM Testing Guide

The timepoint-daedalus project supports **both dry-run testing (fast, free)** and **real LLM testing (slow, costs money)**.

## ğŸš€ Quick Start

### Option 1: Dry-Run Testing (Recommended for Development)
```bash
# Fast, free, deterministic tests
pytest --cov
```

### Option 2: Real LLM Testing (When you want to test actual AI responses)
```bash
# 1. Get API key from https://openrouter.ai/keys
# 2. Set environment variable
export OPENROUTER_API_KEY="your_api_key_here"

# 3. Run tests with real LLM calls
pytest test_framework.py::test_llm_methods --verbose-tests -v

# Or use the convenience script
./test_real_llm.py
```

## ğŸ“Š Comparison

| Feature | Dry-Run Mode | Real LLM Mode |
|---------|--------------|----------------|
| **Speed** | âš¡ ~3 seconds | ğŸŒ ~30-60 seconds |
| **Cost** | ğŸ’° Free | ğŸ’¸ $0.01-0.05 per test run |
| **Deterministic** | âœ… Yes | âŒ No (LLM responses vary) |
| **API Required** | âŒ No | âœ… OpenRouter API key |
| **Internet Required** | âŒ No | âœ… Yes |
| **CI/CD Friendly** | âœ… Yes | âŒ No |

## ğŸ§ª Test Coverage

- **Dry-run mode**: 76% coverage on llm.py (tests logic, not API calls)
- **Real LLM mode**: 100% coverage on llm.py (tests actual API integration)

## ğŸ”§ API Setup

1. **Sign up** at [OpenRouter.ai](https://openrouter.ai/)
2. **Get API key** from [Keys page](https://openrouter.ai/keys)
3. **Set environment variable**:
   ```bash
   export OPENROUTER_API_KEY="sk-or-v1-xxxxxxxxxxxxx"
   ```
4. **Verify setup**:
   ```bash
   python -c "import os; print('API key set:', bool(os.getenv('OPENROUTER_API_KEY')))"
   ```

## ğŸƒ Running Real LLM Tests

### Individual Test
```bash
pytest test_framework.py::test_llm_methods --verbose-tests -v
```

### Full Suite with Real LLM
```bash
export OPENROUTER_API_KEY="your_key"
pytest --cov --verbose-tests
```

### Integration Tests Only
```bash
export OPENROUTER_API_KEY="your_key"
pytest -m integration --verbose-tests -v
```

## ğŸ“ˆ Expected Output

### Dry-Run Mode
```
ğŸ§ª USING DRY-RUN LLM CLIENT (no API key - set OPENROUTER_API_KEY for real calls)
Testing LLM methods
Cost: $0.0000, Tokens: 0
âœ“ Dry-run LLM test passed
âœ“ test_llm_methods passed
```

### Real LLM Mode
```
ğŸ”¥ USING REAL LLM CLIENT (API key detected)
Testing LLM methods
Testing entity population...
Testing consistency validation...
Cost: $0.0123, Tokens: 1234
âœ“ Real LLM test passed (cost: $0.0123)
âœ“ test_llm_methods passed
```

## âš ï¸ Important Notes

- **Costs add up**: Each test run costs ~$0.01-0.05
- **Rate limits**: OpenRouter has rate limits - don't run tests excessively
- **CI/CD**: Use dry-run mode for automated testing
- **Flaky tests**: Real LLM responses can vary, making tests less deterministic

## ğŸ”„ Switching Between Modes

The tests automatically detect which mode to use:

- **API key present** â†’ Real LLM calls
- **No API key** â†’ Dry-run mode

You can force dry-run mode even with an API key:
```bash
pytest test_framework.py::test_llm_methods -k "dry_run" -v
```

## ğŸ¯ When to Use Real LLM Testing

âœ… **Use real LLM testing when:**
- Testing actual AI response quality
- Validating structured output parsing
- Checking API integration
- Before production deployment

âŒ **Use dry-run testing when:**
- Developing new features
- Running in CI/CD
- Quick feedback during coding
- Cost-conscious testing
