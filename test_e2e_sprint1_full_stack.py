"""
Sprint 1.5 E2E Integration Test

Tests the complete Sprint 1 stack:
- World creation
- Horizontal generation (variations)
- Vertical generation (temporal depth)
- Progress tracking
- Fault handling
- Checkpoint management
"""

import pytest
import tempfile
from pathlib import Path

from generation import (
    WorldManager,
    SimulationConfig,
    HorizontalGenerator,
    VerticalGenerator,
    ProgressTracker,
    FaultHandler,
    CheckpointManager
)


class TestSprint1Integration:
    """Integration tests for Sprint 1 components"""

    def test_world_manager_integration(self):
        """Test world manager creates and manages worlds"""
        with tempfile.TemporaryDirectory() as tmpdir:
            manager = WorldManager(base_path=tmpdir)

            # Create world
            world = manager.create_world("test_world_integration")
            assert world.world_id == "test_world_integration"

            # List worlds
            worlds = manager.list_worlds()
            assert len(worlds) == 1
            assert worlds[0].world_id == "test_world_integration"

            # Delete world
            manager.delete_world("test_world_integration", confirm=True)
            worlds = manager.list_worlds()
            assert len(worlds) == 0

    def test_horizontal_generation_integration(self):
        """Test horizontal generator creates variations"""
        generator = HorizontalGenerator()
        base_config = SimulationConfig.example_board_meeting()

        # Generate 5 variations (small number for fast test)
        variations = generator.generate_variations(
            base_config=base_config,
            count=5,
            strategies=["vary_personalities"]
        )

        assert len(variations) == 5

        # Verify each variation has unique world_id
        world_ids = [v.world_id for v in variations]
        assert len(set(world_ids)) == 5

        # Check stats
        stats = generator.get_generation_stats()
        assert stats["variations_created"] == 5

    def test_vertical_generation_integration(self):
        """Test vertical generator expands temporal depth"""
        generator = VerticalGenerator()
        base_config = SimulationConfig.example_jefferson_dinner()

        # Expand temporal depth
        expanded = generator.generate_temporal_depth(
            base_config=base_config,
            before_count=3,
            after_count=2,
            strategy="progressive_training"
        )

        assert expanded.timepoints.before_count == 3
        assert expanded.timepoints.after_count == 2

        # Check stats
        stats = generator.get_generation_stats()
        assert stats["timepoints_added_before"] == 3
        assert stats["timepoints_added_after"] == 2
        assert stats["cost_savings_estimated"] > 0.0

    def test_progress_tracker_integration(self):
        """Test progress tracker during generation"""
        tracker = ProgressTracker(total_entities=10, total_timepoints=5)
        tracker.start()

        # Simulate generation progress
        for i in range(10):
            tracker.update_entity_generated()
            tracker.update_tokens(500)

        for i in range(5):
            tracker.update_timepoint_generated()
            tracker.update_tokens(1000)

        tracker.complete()

        # Verify stats
        summary = tracker.get_summary()
        assert summary["entities_generated"] == 10
        assert summary["timepoints_generated"] == 5
        assert summary["tokens_consumed"] == 10 * 500 + 5 * 1000
        assert summary["entity_success_rate"] == 1.0

    def test_fault_handler_integration(self):
        """Test fault handler with retry logic"""
        handler = FaultHandler(
            max_retries=2,
            initial_backoff=0.01
        )

        call_count = [0]

        def flaky_operation():
            call_count[0] += 1
            if call_count[0] < 2:
                raise Exception("Rate limit exceeded")
            return "success"

        result = handler.with_retry(flaky_operation)
        assert result == "success"
        assert call_count[0] == 2

        # Check error summary
        summary = handler.get_error_summary()
        assert summary["total_errors"] == 1

    def test_checkpoint_manager_integration(self):
        """Test checkpoint manager for long-running jobs"""
        with tempfile.TemporaryDirectory() as tmpdir:
            manager = CheckpointManager(
                checkpoint_dir=tmpdir,
                auto_save_interval=5
            )

            # Create checkpoint
            manager.create_checkpoint("job_integration", metadata={"test": True})

            # Simulate generation with checkpoints
            for i in range(15):
                manager.update_progress("job_integration", items_completed=i+1)
                if manager.should_save_checkpoint("job_integration"):
                    manager.save_checkpoint("job_integration", state={"step": i})

            # Should have saved at 5, 10, 15
            checkpoint = manager.load_checkpoint("job_integration")
            assert checkpoint["items_completed"] == 15
            assert checkpoint["state"]["step"] == 14  # Last saved at i=14

    def test_full_stack_integration(self):
        """
        Test complete Sprint 1 stack integration.

        This is a simplified version that tests integration without LLM calls.
        """
        with tempfile.TemporaryDirectory() as tmpdir:
            # Step 1: Create world
            world_manager = WorldManager(base_path=tmpdir)
            world = world_manager.create_world("sprint1_test")
            assert world.world_id == "sprint1_test"

            # Step 2: Generate horizontal variations
            h_generator = HorizontalGenerator()
            base_config = SimulationConfig.example_board_meeting()

            variations = h_generator.generate_variations(
                base_config=base_config,
                count=3,  # Small number for fast test
                strategies=["vary_personalities"]
            )

            assert len(variations) == 3

            # Step 3: Generate vertical expansion
            v_generator = VerticalGenerator()
            base_config_v = SimulationConfig.example_jefferson_dinner()

            expanded = v_generator.generate_temporal_depth(
                base_config=base_config_v,
                before_count=2,
                after_count=2,
                strategy="progressive_training"
            )

            assert expanded.timepoints.before_count == 2
            assert expanded.timepoints.after_count == 2

            # Step 4: Track progress
            tracker = ProgressTracker(total_entities=3, total_timepoints=2)
            tracker.start()
            tracker.update_entity_generated(count=3)
            tracker.update_timepoint_generated(count=2)
            tracker.complete()

            summary = tracker.get_summary()
            assert summary["entities_generated"] == 3
            assert summary["timepoints_generated"] == 2

            # Step 5: Checkpoint management
            checkpoint_manager = CheckpointManager(checkpoint_dir=tmpdir)
            checkpoint_manager.create_checkpoint(
                "sprint1_job",
                metadata={"variations": 3, "expanded": True}
            )
            checkpoint_manager.save_checkpoint(
                "sprint1_job",
                state={"completed": True}
            )

            loaded = checkpoint_manager.load_checkpoint("sprint1_job")
            assert loaded["metadata"]["variations"] == 3

            # Step 6: Cleanup
            world_manager.delete_world("sprint1_test", confirm=True)
            worlds = world_manager.list_worlds()
            assert len(worlds) == 0


class TestComponentInteraction:
    """Test interactions between Sprint 1 components"""

    def test_horizontal_with_progress_tracking(self):
        """Test horizontal generation with progress tracking"""
        generator = HorizontalGenerator()
        base_config = SimulationConfig.example_board_meeting()

        tracker = ProgressTracker(total_entities=5)
        tracker.start()

        def progress_callback(state):
            # Callback receives progress updates
            assert "overall_progress_percent" in state

        tracker.progress_callback = progress_callback

        variations = generator.generate_variations(
            base_config=base_config,
            count=5,
            strategies=["vary_personalities"]
        )

        # Simulate progress updates
        for _ in variations:
            tracker.update_entity_generated()

        tracker.complete()

        summary = tracker.get_summary()
        assert summary["entities_generated"] == 5

    def test_vertical_with_fault_handling(self):
        """Test vertical generation with fault handling"""
        generator = VerticalGenerator()
        handler = FaultHandler(max_retries=2, initial_backoff=0.01)

        def generate_with_retry():
            base_config = SimulationConfig.example_jefferson_dinner()
            return generator.generate_temporal_depth(
                base_config=base_config,
                before_count=2,
                after_count=2
            )

        result = handler.with_retry(generate_with_retry)
        assert result.timepoints.before_count == 2
        assert result.timepoints.after_count == 2

    def test_generation_with_checkpointing(self):
        """Test generation workflow with checkpointing"""
        with tempfile.TemporaryDirectory() as tmpdir:
            checkpoint_manager = CheckpointManager(
                checkpoint_dir=tmpdir,
                auto_save_interval=2
            )

            # Start job
            checkpoint_manager.create_checkpoint(
                "gen_job",
                metadata={"total": 6}
            )

            # Simulate generation with checkpoints
            generator = HorizontalGenerator()
            base_config = SimulationConfig.example_board_meeting()

            variations = []
            for i in range(6):
                variation = generator.generate_variations(
                    base_config=base_config,
                    count=1,
                    strategies=["vary_personalities"]
                )[0]
                variations.append(variation)

                checkpoint_manager.update_progress("gen_job", items_completed=i+1)
                if checkpoint_manager.should_save_checkpoint("gen_job"):
                    checkpoint_manager.save_checkpoint(
                        "gen_job",
                        state={"variations": [v.world_id for v in variations]}
                    )

            # Verify checkpoint
            checkpoint = checkpoint_manager.load_checkpoint("gen_job")
            assert checkpoint["items_completed"] == 6
            assert len(checkpoint["state"]["variations"]) == 6


@pytest.mark.integration
class TestSprint1Acceptance:
    """Sprint 1 acceptance criteria validation"""

    def test_can_create_and_manage_worlds(self):
        """Acceptance: Can create/delete worlds"""
        with tempfile.TemporaryDirectory() as tmpdir:
            manager = WorldManager(base_path=tmpdir)

            # Create
            world = manager.create_world("acceptance_world")
            assert world.world_id == "acceptance_world"

            # List
            worlds = manager.list_worlds()
            assert any(w.world_id == "acceptance_world" for w in worlds)

            # Delete
            manager.delete_world("acceptance_world", confirm=True)
            worlds = manager.list_worlds()
            assert not any(w.world_id == "acceptance_world" for w in worlds)

    def test_can_generate_variations(self):
        """Acceptance: Can generate 10+ variations reliably"""
        generator = HorizontalGenerator()
        base_config = SimulationConfig.example_board_meeting()

        variations = generator.generate_variations(
            base_config=base_config,
            count=10,
            strategies=["vary_personalities", "vary_outcomes"]
        )

        assert len(variations) >= 10

        # Verify variations are unique
        world_ids = [v.world_id for v in variations]
        assert len(set(world_ids)) == len(variations)

    def test_can_expand_temporal_depth(self):
        """Acceptance: Can generate deep temporal context"""
        generator = VerticalGenerator()
        base_config = SimulationConfig.example_jefferson_dinner()

        expanded = generator.generate_temporal_depth(
            base_config=base_config,
            before_count=5,
            after_count=5,
            strategy="progressive_training"
        )

        assert expanded.timepoints.before_count == 5
        assert expanded.timepoints.after_count == 5

        # Verify cost savings estimation
        stats = generator.get_generation_stats()
        assert stats["cost_savings_estimated"] > 0.5  # At least 50% savings

    def test_progress_tracking_works(self):
        """Acceptance: Progress tracking works for 10+ item generations"""
        tracker = ProgressTracker(total_entities=10, total_timepoints=10)
        tracker.start()

        # Simulate 10 entity generations
        for i in range(10):
            tracker.update_entity_generated()
            tracker.update_tokens(1000)

        # Simulate 10 timepoint generations
        for i in range(10):
            tracker.update_timepoint_generated()
            tracker.update_tokens(500)

        tracker.complete()

        summary = tracker.get_summary()
        assert summary["entities_generated"] == 10
        assert summary["timepoints_generated"] == 10
        assert summary["overall_progress_percent"] == 100.0

    def test_fault_recovery_works(self):
        """Acceptance: Fault recovery with checkpoint/resume"""
        with tempfile.TemporaryDirectory() as tmpdir:
            manager = CheckpointManager(checkpoint_dir=tmpdir)

            # Start job
            manager.create_checkpoint("fault_test", metadata={"total": 10})

            # Process first 5 items
            for i in range(5):
                manager.update_progress("fault_test", items_completed=i+1)
                manager.save_checkpoint("fault_test", state={"processed": i+1})

            # Simulate crash and restart
            checkpoint = manager.load_checkpoint("fault_test")
            resume_from = checkpoint["items_completed"]
            assert resume_from == 5

            # Continue from checkpoint
            for i in range(resume_from, 10):
                manager.update_progress("fault_test", items_completed=i+1)
                manager.save_checkpoint("fault_test", state={"processed": i+1})

            # Verify completion
            assert manager.get_checkpoint_metadata("fault_test")["items_completed"] == 10

    def test_zero_breaking_changes_to_phase_1(self):
        """Acceptance: Zero breaking changes to Phase 1 code"""
        # This test verifies that E2E autopilot tests still pass
        # which validates Phase 1 code is untouched
        # The actual validation happens in the E2E test suite
        assert True  # Placeholder - validated by test_e2e_autopilot.py
