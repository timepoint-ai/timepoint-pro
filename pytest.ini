[tool:pytest]
# Unified Testing Configuration for Timepoint-Pro
# Supports unit, integration, system, and e2e testing with hierarchical test organization

# ============================================================================
# Test Discovery
# ============================================================================
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# ============================================================================
# Default Test Execution (runs all test levels)
# ============================================================================
addopts =
    -v
    --tb=short
    --durations=10
    --strict-markers
    --strict-config
    --color=yes
    --ignore=logs

# ============================================================================
# Test Markers - Hierarchical Organization
# ============================================================================
markers =
    # Test Level Hierarchy (use these to organize your test suite)
    unit: Unit tests - fast, isolated, no external dependencies (< 100ms)
    integration: Integration tests - multiple components working together (< 5s)
    system: System-level tests - full stack with mocked externals (< 30s)
    e2e: End-to-end tests - complete workflows with real services (> 30s)

    # Performance and Resource Markers
    slow: Slow-running tests (> 1 second) - use --skip-slow to skip
    performance: Performance and benchmark tests

    # External Dependencies (expensive/requires credentials)
    llm: Tests making real LLM API calls - use --skip-llm to skip

    # Feature-Specific Markers (for filtering by feature)
    animism: Animistic entity functionality
    temporal: Modal temporal causality
    ai_entity: AI entity service components
    circadian: Circadian activity pattern tests
    real_llm: Tests requiring real LLM API calls

    # Quality Assurance Markers
    validation: Data validation and consistency checks
    safety: Security and safety features
    compliance: Regulatory and compliance requirements

    # SynthasAIzer Paradigm Markers
    synth: SynthasAIzer paradigm tests (envelopes, voices, patches)
    template: Template loading and validation tests
    patch: Patch system tests (catalog, categories, metadata)
    envelope: ADSR envelope lifecycle tests
    voice: Voice mixing control tests

    # Mechanism Coverage Markers (M1-M19)
    mechanism: Core mechanism tests (any M1-M19)
    m1: M1 - Knowledge transfer mechanism
    m2: M2 - Emotional state propagation
    m3: M3 - Relationship formation
    m4: M4 - Decision making under uncertainty
    m5: M5 - Memory consolidation
    m6: M6 - Social influence
    m7: M7 - Belief updating
    m8: M8 - Fear/anxiety embodiment
    m9: M9 - Missing witness inference
    m10: M10 - Scene/atmosphere analysis
    m11: M11 - Dialog generation
    m12: M12 - Alternate history divergence
    m13: M13 - Relationship synthesis
    m14: M14 - Circadian patterns
    m15: M15 - Future prospection (dread/hope)
    m16: M16 - Animistic entities
    m17: M17 - Modal causality (forward/directorial)
    m18: M18 - Tensor maturation
    m19: M19 - Knowledge Extraction mechanism

# ============================================================================
# Warning Filters
# ============================================================================
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    error::ResourceWarning

# ============================================================================
# Logging Configuration
# ============================================================================
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)s] %(name)s: %(message)s
log_cli_date_format = %H:%M:%S

# File logging
log_file = logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)s] %(name)s: %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# ============================================================================
# Async Test Support
# ============================================================================
asyncio_mode = auto

# ============================================================================
# Coverage Configuration (optional - enable with --cov)
# ============================================================================
# Disabled by default - enable with: pytest --cov=. --cov-report=html
# [tool:pytest.coverage]
# source = .
# omit =
#     */tests/*
#     */venv/*
#     */__pycache__/*

# ============================================================================
# Parallel Execution (enable with -n auto or -n <workers>)
# ============================================================================
# Requires: pip install pytest-xdist
# Usage: pytest -n auto

# ============================================================================
# JUnit XML Reports (enable with --junit-xml=reports/junit.xml)
# ============================================================================
junit_family = xunit2

# ============================================================================
# HTML Reports (enable with --html=reports/report.html)
# ============================================================================
# Requires: pip install pytest-html

# ============================================================================
# Doctest Configuration
# ============================================================================
doctest_optionflags =
    NORMALIZE_WHITESPACE
    ELLIPSIS
    IGNORE_EXCEPTION_DETAIL

# ============================================================================
# USAGE EXAMPLES
# ============================================================================
# Run all tests:
#   pytest
#
# Run by test level:
#   pytest -m unit              # Fast unit tests only
#   pytest -m integration       # Integration tests only
#   pytest -m "system or e2e"   # System and E2E tests
#   pytest -m "not e2e"         # Everything except E2E
#
# Skip expensive tests:
#   pytest --skip-slow          # Skip slow tests
#   pytest --skip-llm           # Skip LLM API tests
#   pytest -m "not llm"         # Alternative way to skip LLM
#
# Run by feature:
#   pytest -m animism           # Animistic entity tests
#   pytest -m temporal          # Temporal causality tests
#
# Run SynthasAIzer tests:
#   pytest -m synth             # All synth paradigm tests
#   pytest -m template          # Template loading tests
#   pytest -m patch             # Patch system tests
#   pytest -m envelope          # ADSR envelope tests
#
# Run mechanism tests:
#   pytest -m mechanism         # All M1-M19 mechanism tests
#   pytest -m m9                # M9 missing witness tests
#   pytest -m "m10 or m14"      # M10 and M14 tests
#
# Advanced options:
#   pytest -n auto              # Parallel execution (auto-detect CPUs)
#   pytest --lf                 # Run last failed tests only
#   pytest --ff                 # Run failures first, then rest
#   pytest -k "test_name"       # Filter by test name pattern
#   pytest --real-llm           # Force real LLM calls (requires API key)
#   pytest --strict-quality     # Enforce test quality checks
#
# Generate reports:
#   pytest --junit-xml=reports/junit.xml
#   pytest --html=reports/report.html --self-contained-html
#   pytest --cov=. --cov-report=html
#
# ============================================================================
